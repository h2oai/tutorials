
<!doctype html>

<html>
<head>
  <meta name="viewport" content="width=device-width, minimum-scale=1.0, initial-scale=1.0, user-scalable=yes">
  <meta name="theme-color" content="#4F7DC9">
  <meta charset="UTF-8">
  <title>Time Series Recipe Tutorial</title>
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Source+Code+Pro:400|Roboto:400,300,400italic,500,700|Roboto+Mono">
  <link rel="stylesheet" href="//fonts.googleapis.com/icon?family=Material+Icons">
  <link rel="stylesheet" href="../assets/codelab-elements/codelab-elements.css">
  <style>
    .success {
      color: #1e8e3e;
    }
    .error {
      color: red;
    }
  </style>
</head>
<body>
  <google-codelab-analytics gaid="UA-49880327-14"></google-codelab-analytics>
  <google-codelab title="Time Series Recipe Tutorial"
                  environment="web"
                  feedback-link="">
    
      <google-codelab-step label="Objective" duration="0">
        <p>Time-series forecasting is one of the most common and important tasks in business analytics. The goal of time-series forecasting is to forecast the future values of that series using historical data. Time-series forecasting uses models to predict future values based on previously observed values, also known as extrapolation.</p>
<p>Driverless AI has its own recipes for time-series forecasting that combines advanced time-series analysis and H2O&#39;s own Kaggle Grand Masters&#39; time-series recipes. In this tutorial we will walk through the process of creating a time series experiment and compare the results to a pre-loaded time series experiment based on the same dataset just higher experiment settings.</p>
<p><strong>Note:</strong> We recommend that you go over the entire tutorial first to review all the concepts, that way, once you start the experiment, you will be more familiar with the content.</p>


      </google-codelab-step>
    
      <google-codelab-step label="Prerequisites" duration="0">
        <ul>
<li>You will need the following to be able to do this tutorial:</li>
<li>Basic knowledge of Machine Learning and Statistics</li>
<li>A Driverless AI environment</li>
<li>Basic knowledge of Driverless AI or doing the Automatic Machine Learning Intro tutorial.</li>
</ul>
<p>You can get more information about getting a Driverless AI environment or trial from the following:</p>
<ul>
<li><a href="https://github.com/h2oai/tutorials/blob/master/DriverlessAI/Test-Drive/test-drive.md" target="_blank">A Two Hour Test Drive Session</a><br></li>
<li><a href="https://github.com/h2oai/tutorials/blob/master/DriverlessAI/automatic-ml-intro-tutorial/automatic-ml-intro-tutorial.md#prerequisites" target="_blank">H2O Driverless AI License Key</a></li>
<li><a href="https://github.com/h2oai/tutorials/blob/master/DriverlessAI/automatic-ml-intro-tutorial/automatic-ml-intro-tutorial.md#task-1-get-environment-and-product-tour" target="_blank">H2O Driverless AI Environment and Product Tour</a></li>
</ul>
<p>If you are not familiar with Driverless AI please review and do this tutorial:</p>
<ul>
<li><a href="https://github.com/h2oai/tutorials/blob/master/DriverlessAI/automatic-ml-intro-tutorial/automatic-ml-intro-tutorial.md" target="_blank">Automatic Machine Learning Intro Tutorial</a></li>
</ul>


      </google-codelab-step>
    
      <google-codelab-step label="Task 1: Launch Time Series Experiment" duration="0">
        <h2>About the Dataset</h2>
<p>This dataset contains information about a global retail store. It includes historical data for 45 of its stores located in different regions of the United States from 02-05-2010 to 11-01-2012. Each numbered store contains a number of departments, the stores specific markdowns(promotional) events they have throughout the year which typically happen before prominent holidays such as the Superbowl, Labor Day, Thanksgiving and Christmas. Additional information included are the weekly sales, dates of those sale, the fuel price in the region, consumer price index and unemployment rate. The dataset was used in a Kaggle in 2014 competition with the goal of helping this retail store forecast sales of their stores.</p>
<p>[1] Our training dataset is a synthesis of the csv data sources provided for the Kaggle Store Sales Forecasting competition. The three datasets were train.csv, stores.csv and features.csv.  The train.csv has the store number, department, date, weekly sales and whether or not that day was a holiday. The stores.csv had the types of stores and their size while the features.csv which had additional demographic information about the specific region the store was located in.</p>
<p>The training dataset in this tutorial contains 73,165 rows and a total of 11 features (columns) and is about 5 MB. The test dataset contains about 16,000 rows and a total of 11 features (columns) and is about 1 MB.</p>
<h2>Datasets Overview</h2>
<p>If you are using Aquarium as your environment then the following labs, <strong>Test Drive</strong> and <strong>Introduction to Driverless AI</strong>, will have this tutorials training and test subsets of the Retail Store Forecasting dataset preloaded for you. The datasets will be located on <strong>Datasets Overview</strong> page. You will also see two extra data sets, which you can ignore for now as they are used for another tutorial. To learn more about how to add the two datasets from the DAI file system then see Appendix A: Add the Datasets.</p>
<p>1. Verify that both dataset are on the <strong>Datasets Overview</strong>, your screen should look similar to the  page below:</p>
<p><img alt="retail-store-train-test-datasets" src="img/7b753b452ee4b80a.jpg"></p>
<p>2. Click on the  <strong>walmart_tts_small_train.csv</strong> file, then on <strong>Details</strong>.</p>
<p><img alt="retail-store-train-detail-selection" src="img/133c776600c9621f.jpg"></p>
<p>3. Let&#39;s take a quick look at the columns of the training set:</p>
<p><img alt="retail-store-train-detail-page" src="img/d9833c7fac90daeb.jpg"></p>
<p><em>Things to Note:</em></p>
<ul>
<li><strong>Store</strong> - the store number</li>
<li><strong>Dept</strong> - the department number</li>
<li><strong>Date</strong> - the week</li>
<li><strong>Weekly_Sales</strong> - sales for the given department in the given store, what we are trying to predict<br>MarkDown1-5 - anonymized data related to promotional markdowns that this global retail store is running. MarkDown data is only available after Nov 2011, and is not available for all stores all the time. Any missing value is marked with an NA.</li>
<li><strong>MarkDown1</strong></li>
<li><strong>MarkDown2</strong></li>
<li><strong>MarkDown3</strong></li>
</ul>
<p>4. Continue scrolling the current page to see more columns (image is not included)</p>
<ul>
<li><strong>MarkDown4</strong></li>
<li><strong>MarkDown5</strong></li>
<li><strong>IsHoliday</strong> - whether the week is a holiday week</li>
<li><strong>sample_weight</strong></li>
</ul>
<p>5. Return to the <strong>Datasets</strong> Page</p>
<h2>Launch Experiment</h2>
<p>As mentioned on the objectives, this tutorial includes a pre-ran experiment that has been linked to the <strong>Projects Workspace</strong>. <strong>Projects</strong> is a feature introduced in DAI 1.7.0 and it is a workspace for managing datasets and experiments related to a specific business problem or use case. The <strong>Projects</strong> page allows for easy comparisons of performance and results and identify the best solution for your problem. See Deeper Dive and Resources at the end of this task for additional information on the <strong>Projects Workspace</strong>.</p>
<p>2. Select <strong>Projects</strong> , an image similar to the one below will appear:</p>
<p><img alt="projects-page" src="img/ecf5bd17ab5c8359.jpg"></p>
<p><em>Things to Note:</em></p>
<ol type="1">
<li><strong>Projects</strong>: Projects menu option</li>
<li>Pre-created <strong>Project</strong> which includes:<br><br><ul>
<li><strong>Name</strong> : Project name (Time Series Tutorial)</li>
<li><strong>Description</strong>: Optional (N/A)</li>
<li><strong>Train Datasets</strong>: Number of train datasets (1)</li>
<li><strong>Valid Datasets</strong>: Number of validation datasets (0)</li>
<li><strong>Test Datasets</strong>: Number of test datasets (1)</li>
<li><strong>Experiments</strong>: Number of experiments (1)</li>
</ul>
</li>
<li>Additional options for the created project:<br><br><ul>
<li><strong>Open</strong></li>
<li><strong>Rename</strong></li>
<li><strong>Delete</strong></li>
</ul>
</li>
<li><strong>+New Project</strong>: Option to create a new project</li>
</ol>
<p>3. Open the <strong>Time Series Tutorial</strong>, an image similar to the one below will appear:</p>
<p><img alt="projects-page-time-series" src="img/271e8a134f5a5ebb.jpg"></p>
<p>The project &#34;Time Series Tutorial&#34; has the pre-ran time series experiment linked, this includes:<br>All the datasets used in the pre-ran experiment<br>Completed Experiment</p>
<p>4. Select <strong>New Experiment</strong> , located on the top-right corner of the page.</p>
<p><img alt="projects-new-experiment" src="img/d1707323a5a4cf8b.jpg"></p>
<p>5.  Select <strong>Not Now</strong> on the <strong>First time Driverless AI, Click Yes to get a tour!</strong>. A similar image should appear, then select <strong>Click to select or import a dataset...</strong></p>
<p><img alt="new-project-training-data" src="img/a632192f36310f79.jpg"></p>
<p>6. Select the <code>walmart_tts_small_train.csv</code> dataset:</p>
<p><img alt="new-project-select-train-dataset" src="img/4b3b308ffd83a33.jpg"></p>
<p>Name your experiment: <code>Time Series Forecasting</code></p>
<p>7. A similar experiment page will appear:</p>
<p><img alt="retail-store-predict" src="img/a46b180758e72a02.jpg"></p>
<p>On task 2, we will explore and update the <strong>Time Series Experiment Settings</strong>.</p>
<h2>References</h2>
<p>[1] <a href="https://www.kaggle.com/c/walmart-recruiting-store-sales-forecasting/data" target="_blank">Walmart Recruiting - Stores Sales Forecasting</a></p>
<h2>Deeper Dive and Resources</h2>
<p><a href="http://docs.h2o.ai/driverless-ai/latest-stable/docs/userguide/projects.html?highlight=projects%20workspace" target="_blank">H2O - Projects Workspace </a></p>


      </google-codelab-step>
    
      <google-codelab-step label="Task 2: Time Series Experiment Settings" duration="0">
        <p>In this task, we are going to update the experiment settings. Unlike the other experiments covered in this tutorial series, the experiment settings layout for time series are slightly different, and there is an additional component, time. The following experiment settings will be adjusted to run through the mechanics of running a time series experiment</p>
<p><strong>Experiment settings</strong> to be updated:</p>
<ul>
<li><strong>Test Dataset</strong></li>
<li><strong>Target Column</strong></li>
<li><strong>Weight Column</strong></li>
<li><strong>Time Column</strong></li>
<li><strong>Time Groups</strong></li>
<li><strong>Forecast Horizon</strong></li>
<li><strong>Scorer</strong></li>
<li><strong>Accuracy</strong></li>
<li><strong>Time</strong></li>
<li><strong>Interpretability</strong></li>
</ul>
<p>Below are high level descriptions of the DAI settings that will be updated for this time series tutorial. To learn more about each scorer see the <strong>Deeper Dive and Resources</strong> at the end of this task.</p>
<p><strong>Test Dataset</strong><br>The test dataset is used for testing the modeling pipeline and creating test predictions. The test set is never used during training of the modeling pipeline. (Results are the same whether a test set is provided or not.) If a test dataset is provided, then test set predictions will be available at the end of the experiment. Adding the test dataset will also hint Driverless AI of the expected horizon and gap. Driverless AI measures the length of the Test dataset as well as the timing of when it commences (compared to the end of the training data) to decide on these values.</p>
<p><strong>Weight Column</strong><br>Column that indicates the observation <strong>weight</strong> (a.k.a. sample or row weight), if applicable. This column must be numeric with values &gt;= 0. Rows with higher weights have higher importance. The weight affects model training through a weighted loss function and affects model scoring through weighted metrics. The weight column is not used when making test set predictions, but a weight column (if specified) is used when computing the test score during training.</p>
<p><strong>Time Column</strong><br>Column that provides a time order (time stamps for observations), if applicable. Can improve model performance and model validation accuracy for problems where the target values are auto-correlated with respect to the ordering (per time-series group).</p>
<p>The values in this column must be a datetime format understood by pandas.to_datetime(), like &#34;2017-11-29 00:30:35&#34; or &#34;2017/11/29&#34;, or integer values. If [AUTO] is selected, all string columns are tested for potential date/datetime content and considered as potential time columns. If a time column is found, feature engineering and model validation will respect the causality of time. If [OFF] is selected, no time order is used for modeling and data may be shuffled randomly (any potential temporal causality will be ignored).</p>
<p><strong>Time Groups</strong></p>
<p>Time Groups are categorical columns in the data that can significantly help predict the target variable in time series problems. Examples of time groups would be a combination of customer and product (assuming each has its own history), where you might want to see if a customer wants to buy one of your specific products. You can look into the direct time series and view how many times a customer has bought that particular product in the past time points. The two time groups (customer and product) or multiple time series can be blended together in DAI.</p>
<p><strong>Scorers</strong></p>
<p>A scorer is a function that takes actual and predicted values for a dataset and returns a number. Looking at this single number is the most common way to estimate the generalization performance of a predictive model on unseen data by comparing the model&#39;s predictions on the dataset with its actual values. For a given <strong>scorer</strong>, Driverless AI optimizes the pipeline to end up with the best possible score for this scorer. We highly suggest experimenting with different <strong>scorers</strong> and to study their impact on the resulting models[1].</p>
<p>The scores available in Driverless AI are:</p>
<ul>
<li>GINI : Gini Coefficient</li>
<li>MAE : Mean Absolute Error</li>
<li>MAPE : Mean Absolute Percentage Error</li>
<li>MER : Median Error Rate</li>
<li>MSE : Mean Squared Error</li>
<li>R2 : R Squared</li>
<li>RMSE : Root Mean Square Error</li>
<li>RMSLE : Root Mean Squared Logarithmic Error</li>
<li>RMSPE : Root Mean Square Percentage Error</li>
<li>SMAPE : Symmetric Mean Absolute Percentage Error</li>
</ul>
<p><strong>Forecast Horizon</strong></p>
<p>Amount of time periods to predict</p>
<p>It is important to note that the following settings are essential for the development of a good model. For best model results, it is recommended to use the default settings given by Driverless AI. Please keep in mind that using an environment like Test Drive will limit you to a two-hour lab session. The default settings can lead to a run time of more than two hours.</p>
<p><strong>Accuracy</strong></p>
<p>Accuracy in time series forecasting determines the number of time-based validation splits. It also controls whether sampling will be used, the types of main machine learning models as well as the type of features included.</p>
<p><strong>Time</strong><br>It controls how long (as in how many iterations) Driverless AI will spend on trying to find:</p>
<ol type="1">
<li>The best time series  features</li>
<li>Best models</li>
<li>Best hyper parameters for these models</li>
</ol>
<p><strong>Interpretability</strong></p>
<p>Controls the complexity of the models and features allowed within the experiments (e.g. higher interpretability will generally block complicated features and models).</p>
<p>Now we will update the experiment settings for our retail sales dataset.</p>
<p><img alt="retail-store-experiment-settings" src="img/949f929dde86f331.jpg"></p>
<p>1. Select <strong>Test Dataset</strong>, then select <strong>walmart_tts_small_test.csv</strong></p>
<p><img alt="add-test-set" src="img/e125cb6d906646bb.jpg"></p>
<p>2.  To start the time series experiment you need to select <strong>Time Column</strong>, then select <strong>Date</strong>.</p>
<p><strong>Note:</strong> The date will be defined in the time field, when this is done then Time Series will be enabled, then the  <strong>Time Series Settings</strong> will appear on the top-right side of the page.</p>
<p><img alt="add-time-column" src="img/8eb67afab6dcbd8.jpg"></p>
<p>3. Select <strong>Weight Column</strong>, then select <strong>sample_weight</strong></p>
<p><img alt="add-weight-column" src="img/d9aaedf1f7f00ee2.jpg"></p>
<p>4. Select <strong>Target Column</strong>, then select <strong>Weekly_Sales</strong></p>
<p><img alt="add-target-column" src="img/29c1c5a0d601a83a.jpg"></p>
<p>Under <strong>Time Series Settings</strong> located on the top-right side:</p>
<p>5. Select <strong>Time Groups Columns</strong>, then select the columns below, followed by: <strong>Done</strong>.</p>
<ul>
<li><strong>Store</strong></li>
<li><strong>Dept</strong></li>
<li><strong>Date</strong></li>
</ul>
<p><img alt="add-time-group-columns" src="img/1b220dccc339b6dc.jpg"></p>
<p>6. Select <strong>Forecast Horizon</strong>, make sure the <strong>Forecast Horizon</strong> is <code>26 weeks</code> and the gap between Train/Test Period is <code>0 weeks</code>.</p>
<p><img alt="forecast-horizon-and-gap" src="img/32766db4e81d35c6.jpg"></p>
<p>7. Under <strong>Experiment Settings</strong>, click on <strong>Scorer</strong>,</p>
<p><img alt="expert-settings-scorer" src="img/729bf06e3a525bb7.jpg"></p>
<p>then select <strong>R2</strong> as the scorer:</p>
<p><img alt="add-scorer-r2" src="img/985986e610803aea.jpg"></p>
<p>8. Under <strong>Experiment Settings</strong>, update Accuracy, Time and Interpretability to values below, then click on <strong>Launch Experiment</strong>:</p>
<p><strong>Note:</strong>: These settings were selected to conform to the Aquarium/Test Drive Environment. The goal is to walk-through the mechanics of setting up a time series experiment. Having an interpretability of 10 means that we want a simple model that will be easy to interpret.</p>
<ul>
<li><strong>Accuracy</strong> : 1</li>
<li><strong>Time</strong> : 1</li>
<li><strong>Interpretability</strong> : 10</li>
</ul>
<p><img alt="experiment-settings-6-1-5" src="img/bf121cb0372f2d09.jpg"></p>
<p>9. Now review your experiment settings page and make sure it looks similar to the image below, after, select <strong>Launch Experiment</strong>.</p>
<p><img alt="experiment-page-launch-experiment" src="img/bfcde1c5588088d0.jpg"></p>
<h2>References</h2>
<p>[1] <a href="http://docs.h2o.ai/driverless-ai/latest-stable/docs/userguide/tips-n-tricks.html?highlight=scorer#scorer-tips" target="_blank">H2O&#39;s DAI Scorer Tips</a></p>
<h2>Deeper Dive and Resources</h2>
<ul>
<li><a href="http://docs.h2o.ai/driverless-ai/latest-stable/docs/userguide/scorers.html?highlight=scorer#scorers" target="_blank">H2O&#39;s DAI More on Scores</a></li>
<li><a href="http://docs.h2o.ai/driverless-ai/latest-stable/docs/userguide/time-series.html?highlight=time%20groups" target="_blank">H2O&#39;s Time Series in Driverless AI</a></li>
</ul>


      </google-codelab-step>
    
      <google-codelab-step label="Task 3: Time Series Experiment Concepts" duration="0">
        <h2>Time Series</h2>
<p>Time series is a collection of observations generated sequentially through time. In time series, data is ordered with respect to time, and it is expected that successive observations are dependent, an example is ocean tides[1].</p>
<p>Characteristics of time series data:</p>
<ul>
<li>Natural temporal ordering</li>
<li>Natural one-way ordering of time</li>
<li>Order of time</li>
<li>Stationary: do not have trend or seasonal effects</li>
<li>Non-stationary: contain trends and seasonality</li>
<li>Observations close together in time will be more closely related than that data further apart</li>
<li>Predictions for a given period are made on the natural one-way order rather than future events</li>
<li>Time Series is different from cross-section studies where a group of people from a particular point of time are studied, this does not follow a natural order</li>
<li>Time series is different to data collected with time differences due to geographical locations</li>
</ul>
<p>The plots below are examples of non-stationary time series where the time series dataset shows seasonality and trends.</p>
<p><img alt="time-series-seasonal-and-linear" src="img/1f64233acf79d6f.jpg"></p>
<h2>Time Series Analysis</h2>
<p>Time series analysis helps answer questions such as what is the causal effect on a variable Y of a change in X overtime? The goal is to understand the dataset to build mathematical models that provide plausible interpretations of the problem domain. In time-series analysis you are trying to determine the components of the dataset in terms of seasonal patterns, trends, relation to external factors. Models are developed to best capture or describe an observed time series in order to understand the underlying causes[1].</p>
<h2>Time Series Forecasting</h2>
<p>Time-series forecasting is one of the most common and important tasks in business analytics. The goal of time-series forecasting is to forecast the future values of that series using historical data. Time-series forecasting uses models to predict future values based on previously observed values, also known as extrapolation.</p>
<p>Here is a short list of the many real-world applications of time-series:</p>
<ul>
<li>Sales</li>
<li>Weather</li>
<li>Stock market</li>
<li>Energy demand</li>
</ul>
<h2>Time Series Forecasting in DAI</h2>
<p>Driverless AI has its own recipes for time-series forecasting that combines advanced time-series analysis and H2O&#39;s own Kaggle Grand Masters&#39; time-series recipes.</p>
<p>These are the key features/recipes that make the automation possible:</p>
<ul>
<li>Automatic handling of time groups (e.g., different stores and departments)</li>
<li>Robust time-series validation</li>
<li>Accounts for gaps and forecast horizon</li>
<li>Uses past information only (i.e., no data leakage)</li>
<li>Time-series-specific feature engineering recipes</li>
<li>Date features like day of week, day of month, etc.</li>
<li>AutoRegressive features, like optimal lag and lag-features interaction</li>
<li>Different types of exponentially weighted moving averages</li>
<li>Aggregation of past information (different time groups and time intervals)</li>
<li>Target transformations and differentiation</li>
<li>Integration with existing feature engineering functions (recipes and optimization)</li>
<li>Automatic pipeline generation<h2>DAI  Modeling Approach</h2>
</li>
</ul>
<p>Driverless AI uses GBMs, GLMs and neural networks with a focus on time-series-specific feature engineering. The feature engineering includes:</p>
<ul>
<li>Autoregressive elements: creating lag variables</li>
<li>Aggregated features on lagged variables: moving averages, exponential smoothing descriptive statistics, correlations</li>
<li>Date-specific features: week number, day of week, month, year</li>
<li>Target transformations: Integration/Differentiation, univariate transforms (like logs, square roots). This approach is combined with AutoDL features as part of the genetic algorithm. The selection is still based on validation accuracy. In other words, the same transformations/genes apply; plus there are new transformations that come from time series. Some transformations (like target encoding) are deactivated.</li>
<li>When running a time-series experiment, Driverless AI builds multiple models by rolling the validation window back in time (and potentially using less and less training data).<h2>Gap and Horizon</h2>
</li>
</ul>
<p>The guiding principle for properly modeling a time series forecasting problem is to use the historical data in the model training dataset such that it mimics the data/information environment at scoring time (i.e. deployed predictions). Specifically, you want to partition the training set to account for:</p>
<ol type="1">
<li>The information available to the model when making predictions</li>
<li>The length of predictions to make.<br>Given a training dataset, gap and prediction length are parameters that determine how to split the training dataset into training samples and validation samples.</li>
</ol>
<p><strong>Gap</strong>: is the amount of missing time bins between the end of a training set and the start of test set (with regards to time). For example:</p>
<ul>
<li>Assume there are daily data with days 1/1/2019, 2/1/2019, 3/1/2019, 4/1/2019 in train. There are 4 days in total for training .</li>
<li>In addition the test data will start from 6/1/2019. There is only 1 day in the test data.</li>
<li>The previous day (5/1/2019) does not belong to the train data. It is a day that cannot be used for training (i.e because information from that day may not be available at scoring time). This day cannot be used to derive information (such as historical lags) for the test data either.</li>
<li>Here the time bin (or time unit) is 1 day. This is the time interval that separates the different samples/rows in the data.</li>
<li>In summary there are 4 time bins/units for the train data and 1 time bin/unit for the test data plus the Gap.</li>
<li>In order to estimate the Gap between the end of the train data and the beginning of the test data, the following formula is applied.</li>
<li>Gap = min(time bin test) - max(time bin train) - 1.<br>in this case min(time bin test) is 6 (or 6/1/2019). This is the earliest (and only) day in the test data max(time bin train) is 4 (or 4/1/2019). This is the latest (or the most recent) day in the train data.</li>
<li>Thefore the GAP is 1 time bin (or 1 day in this case), because Gap = 6 - 4 - 1 or Gap = 1</li>
</ul>
<p><img alt="time-series-gap" src="img/d1dbb835e855e1dc.jpg"></p>
<p>Quite often, it is not possible to have the most recent data available when applying a model (or it is costly to update the data table too often); hence models need to be built accounting for a &#34;future gap&#34;. For example if it takes a week to update a certain data table, ideally we would like to predict &#34;7 days ahead&#34; with the data as it is &#34;today&#34;; hence a gap of 7 days would be sensible. Not specifying a gap and predicting 7 days ahead with the data as it is 7 days ahead is unrealistic (and cannot happen as we update the data on a weekly basis in this example).</p>
<p>Similarly, gap can be used for those who want to forecast further in advance. For example, users want to know what will happen in 7 days in the future, they will set the gap to 7 days.</p>
<p><strong>Horizon</strong>  (or prediction length) is the period that the test data spans for (for example, one day, one week, etc.). In other words it is the future period that the model can make predictions for.</p>
<p><img alt="time-series-horizon" src="img/d776869dd18ad4ed.jpg"></p>
<p>The periodicity of updating the data may require model predictions to account for significant time in the future. In an ideal world where data can be updated very quickly, predictions can always be made having the most recent data available. In this scenario there is no need for a model to be able to predict cases that are well into the future, but rather focus on maximizing its ability to predict short term. However this is not always the case, and a model needs to be able to make predictions that span deep into the future because it may be too costly to make predictions every single day after the data gets updated.<br>In addition, each future data point is not the same. For example, predicting tomorrow with today&#39;s data is easier than predicting 2 days ahead with today&#39;s data. Hence specifying the <strong>horizon</strong> can facilitate building models that optimize prediction accuracy for these future time intervals.</p>
<h2>Groups</h2>
<p>Time-series has multiple groups, which combines multiple time-series together. Groups are categorical columns in the data that can significantly help predict the target variable in time series problems. For example, one may need to predict sales, given information about stores and products or just stores or just products. Being able to identify that the combination of store and products can lead to very different sales is key for predicting the target variable, as a big store or a popular product will have higher sales than a small store and/or with unpopular products.</p>
<p>For example, if we don&#39;t know that the store is available in the data, and we try to see the distribution of sales along time (with all stores mixed together), it may look like the chart below:<br><img alt="time-series-sales-per-day-all-groups" src="img/82923064ebbdcb2e.jpg"><br>Note the format <strong>Date(Time)</strong>, <strong>Group(Groups)</strong> and <strong>Target(Sales)</strong> plus other independent features. This is the ideal format the data needs to be in or order for DAI Time-Series to work.</p>
<h2>Lag</h2>
<p>The primary generated time series features are lag features, which are a variable&#39;s past values. At a given sample with time stamp <em>t</em>, features at some time difference <em>T</em>(lag) in the past are considered. For example, if the sales today are 300, and sales of yesterday are 250, then the lag of one day for sales is 250. Lags can be created on any feature as well as on the target.</p>
<p><img alt="time-series-lag" src="img/9894ec93a4a19c58.jpg"></p>
<p><strong>Note:</strong> The top section is the original dataset with training data, the gap and the period we want to predict is also known as the test.</p>
<ul>
<li>The training data expands a certain number of time units. The time units can be anything, it can be years, months, weeks, seconds or just an integer value that increments over time. When the training data stops, then the test data period begins, these are the periods we want to make predictions for.</li>
<li>Another item to note is the gap, which DAI accounts for. The gap is when you don&#39;t have the most recent information available when you want to make predictions. For instance, when we want to make a prediction for tomorrow but we only have data from yesterday because our dataset was not updated today. This means that the only data available to make the predictions are all the data up to yesterday.<br>The second section of the image is what happens behind the scenes in DAI to optimize for the top dataset. Here a window which includes test and gap are taken and DAI tries to replicate them internally. We go to the most recent part of the training data and form a validation dataset. This new validation dataset will be of the same size as the test dataset with an artificially added gap so that it matches the original window. Then DAI uses any remaining periods to generate periods to form a training dataset.</li>
</ul>
<p>As previously noted, the training dataset is appropriately split such that the amount of validation data samples equals that of the testing dataset samples. If we want to determine valid lags, we must consider what happens when we will evaluate our model on the testing dataset. Essentially, the minimum lag size must be greater than the gap size.</p>
<p>Aside from the minimum useable lag, Driverless AI attempts to discover predictive lag sizes based on auto-correlation.&#34;Lagging&#34; variables are important in time series because knowing what happened in different time periods in the past can greatly facilitate predictions for the future.</p>
<h2>Validation Schemas</h2>
<p>DAI uses the most recent training data as the validation data. Data can be validated by the following validation schemas:</p>
<ul>
<li><strong>Time split</strong><ul>
<li>Single Time</li>
</ul>
</li>
<li><strong>Multi window</strong><ul>
<li>Rolling Window with adjusting traninging size</li>
<li>Rolling window with constant training size</li>
</ul>
</li>
<li><strong>Random K intervals</strong></li>
</ul>
<p>Below is an example of a time series dataset, we will use it to showcase some of the validation schemas:</p>
<p><img alt="validation-schema-dataset" src="img/b8bc64feed295af9.jpg"></p>
<p><strong>Time Split</strong></p>
<p>The number of time splits is highly dependent on the value of accuracy set on the experiment page. If the accuracy is set low when setting up the experiment, then DAI selects a single time split which in turn will only generate one model for validation. A single time split takes the most recent data and makes it the validation data. The validation data will be the same size as the forecast horizon and it will include a gap if there was a gap.</p>
<p>Single Time Split</p>
<p><img alt="validation-schema-time-split" src="img/bb2eac23bda18533.jpg"></p>
<p>When accuracy is set to higher values, then the number of time splits increases and DAI does a more thorough cross validation and we start generating multiple folds with a rolling window. A rolling window means that we keep shifting the validation set to the past and we use again any data before that for a training dataset, this process will be done multiple times. For example when Accuracy is set to 10, then the number of time splits increases to 6, this means there will be more rolling windows.  The number of rolling windows is a factor of accuracy.</p>
<p><strong>Multi window</strong></p>
<p><img alt="validation-schema-multi-window" src="img/a42b399457a8a0bd.jpg"></p>
<h2>Time Series Feature Engineering</h2>
<p>The following are the types of time series families that DAI creates:</p>
<p><strong>Date Decomposition</strong> extracts:</p>
<ul>
<li>Year</li>
<li>Quarter</li>
<li>Month</li>
<li>Day</li>
<li>Day of Year</li>
<li>Week</li>
<li>Week day</li>
<li>Hour</li>
<li>Minute</li>
<li>Second</li>
<li>Holidays: Includes Holidays based on calendars from different countries</li>
</ul>
<p><img alt="feature-engineering-date-decomposition" src="img/d8345a40c6e55db2.jpg"></p>
<p><strong>Lags</strong> : If you wanted to predict <strong>target</strong> we can use the values of yesterday(lag1), two days ago(lag2), three days ago(lag3) as features.</p>
<p><img alt="feature-engineering-lags" src="img/d8f185f0141dd71d.jpg"></p>
<p><strong>Windows</strong>: Another family of features are windows, windows are combinations of different lags. For example we can take an average or a moving average of three lags together such as  lag1, lag2 and lag3. It is good to be able to see the difference between a standard average and a weighted moving average where the highest observation has the highest weight than the other one, the idea being that what happened most recently will have a bigger impact on the target compared to events that happened further away in the past. We can also do this by applying exponential smoothing, where we apply an exponential decay of .95 (hyper parameter a), where we give the most recent observation higher importance than the one that is further in the past.</p>
<p>Windows can be also used to obtain other descriptive statistics such as:</p>
<ul>
<li>Max</li>
<li>Min</li>
<li>Median</li>
<li>Standard Deviation</li>
<li>Kurtosis</li>
<li>Skewness</li>
</ul>
<p><img alt="feature-engineering-windows" src="img/c2d3ddaaec166f37.jpg"></p>
<p><strong>Interactions</strong> : Interactions are interactions between lag values, these are also features that are created in order to deseasonalize the data to focus more on the differences between the data points than then trend. For example, calculating the difference between lag1 and lag2 ( Diff1 = lag1 - lag2) or looking proportionally how the target is changing in the past (Div1= lag1/lag2).</p>
<p><img alt="feature-engineering-interactions" src="img/55732bfe62d26fc4.jpg"></p>
<p><strong>Trends</strong>: Trends or correlation is used as another feature where we take the lag values and plot them against time and observe the trend created(R2 value). Linear regression can also be used where the coefficient or slope is taken and then it is used as a feature to solve the trend/tendency of the time series to go up or down.</p>
<p><img alt="feature-engineering-trends" src="img/519b8942d195878f.jpg"></p>
<p><strong>Target transformations</strong>:  DAI also does target transformation so that instead of modeling on the target(label), we can model on the square root of the target. For example when using RMSLE as the scorer, DAI converts the target to the log of the target.<br>Other transformations include:<br>Square Root<br>Log</p>
<p><img alt="feature-engineering-target-transformations" src="img/c86d46ac3770e29e.jpg"></p>
<h2>References</h2>
<p>[1] <a href="https://www.goodreads.com/book/show/1827184.Applied_Time_Series_and_Box_Jenkins_Models" target="_blank">Applied Time Series and Box-Jenkins Models by Walter Vandaele page 3-5</a></p>
<h2>Deeper Dive and Resources</h2>
<ul>
<li><a href="http://docs.h2o.ai/driverless-ai/latest-stable/docs/userguide/transformations.html?highlight=interactions" target="_blank">Driverless AI Transformations</a></li>
<li><a href="http://docs.h2o.ai/driverless-ai/latest-stable/docs/userguide/time-series.html?highlight=time%20groups" target="_blank">H2O&#39;s Time Series in Driverless AI</a></li>
<li><a href="https://www.youtube.com/watch?v=EGVY7-Spv8E" target="_blank">Time Series with Driverless AI - Marios Michailidis and Mathias MÃ¼ller - H2O AI World London 2018</a></li>
<li><a href="https://github.com/h2oai/h2oai/blob/dev/docs/time-series.rst#gap-and-horizon" target="_blank">Time Series in Driverless AI - GitHub Docs </a></li>
</ul>


      </google-codelab-step>
    
      <google-codelab-step label="Task 4: Experiment Results Summary" duration="0">
        <p>At the end of the experiment, a similar page will appear:</p>
<p><img alt="experiment-results-summary-page" src="img/cacaee5594f8a5c3.jpg"></p>
<p><em>Things to Note:</em></p>
<ol type="1">
<li>Status: Complete<ul>
<li><strong>Deploy To Cloud</strong></li>
<li><strong>Interpret this Mode</strong>l - Launches Model Interpretation on time series data for multiple groups</li>
<li><strong>Diagnose Model on New Dataset...</strong> -  allows you to view model performance for multiple scorers based on existing model and dataset</li>
<li><strong>Score on another Dataset</strong> - After you generate a model, you can use that model to make predictions on another dataset</li>
<li><strong>Transform Another Dataset..</strong> - Not available for Time Series experiments</li>
<li><strong>Download Predictions</strong><ul>
<li>Training Predictions - In csv format, available if a validation set was NOT provided</li>
<li>Test Set Predictions - In csv format, available if a validation set was provided</li>
</ul>
</li>
<li><strong>Download Python Scoring Pipeline</strong> - A standalone Python scoring pipeline for H2O Driverless AI</li>
<li><strong>Build MOJO Scoring Pipeline</strong> - A standalone Model Object, Optimized scoring pipeline</li>
<li><strong>Download Experiment Summary</strong> - An experiment summary is available for each completed experiment as zip file</li>
<li><strong>Download Logs</strong></li>
<li><strong>Download Autoreport</strong></li>
</ul>
</li>
<li>Iteration Data - Validation<ul>
<li>Validation Score - 0.7642</li>
<li>Model Type: XGBoostGBM</li>
<li>Variable Importance</li>
</ul>
</li>
<li>Summary:</li>
<li>Summary: See image below:</li>
</ol>
<p><img alt="experiment-results-summary" src="img/62b0fd618937c061.jpg"></p>
<ul>
<li>Actual vs Predicted: See image below:</li>
</ul>
<p><img alt="experiment-results-actual-vs-predicted" src="img/1668cb592917393a.jpg"></p>
<ul>
<li>Residuals : See image below:</li>
</ul>
<p><img alt="experiment-results-residuals" src="img/2b1c7c6daa3721bf.jpg"></p>
<h2>Deeper Dive and Resources</h2>
<ul>
<li><a href="http://docs.h2o.ai/driverless-ai/latest-stable/docs/userguide/interpreting.html#interpret-this-model-button-time-series" target="_blank">Interpreting this Model Button - Time Series</a></li>
</ul>


      </google-codelab-step>
    
      <google-codelab-step label="Task 5: Model Interpretability" duration="0">
        <p>1. On the <strong>Status: Complete</strong> Options: select <strong>Interpret this Model</strong></p>
<p><img alt="interpret-this-model" src="img/e80fcad0faccc136.jpg"></p>
<p>2. While the model is being interpreted an image similar to the one below will appear:</p>
<p><img alt="mli-interpret-model" src="img/54aebc176f612515.jpg"></p>
<p>3. Once the &#34;MLI Experiment is Finished&#34; page comes up, select <strong>Yes</strong>, and an image similar to the one below will appear:</p>
<p><img alt="mli-time-series-explanations-and-debugging-1" src="img/9c423b412358f159.jpg"></p>
<p><img alt="mli-time-series-explanations-and-debugging-2" src="img/40de45acc48981ff.jpg"></p>
<p><em>Things to Note:</em></p>
<ol type="1">
<li><strong>MLI TS HELP</strong><ul>
<li><strong>Help Panel</strong> : This panel describes how to read and use the Time Series MLI page.</li>
<li><strong>Hide Panel</strong> : To hide Help Panel, click on Hide Panel</li>
<li><strong>Add Panel</strong> :  add a new MLI Time Series panel. This allows you to compare different groups in the same model and also provides the flexibility to do a &#34;side-by-side&#34; comparison between different models.</li>
<li><strong>MLI TS Docs</strong> : A link to the &#34;Machine Learning Interpretability with Driverless AI&#34; booklet.</li>
</ul>
</li>
<li><strong>Time Series Model</strong><ul>
<li><strong>Download Logs</strong> : Download a zip file of the logs that were generated during this interpretation</li>
<li><strong>Show Summary</strong> : Button provides details about the experiment settings that were used</li>
<li><strong>Download Group Metrics</strong> : retrieve the averages of each group&#39;s scorer, as well as each group&#39;s sample size.</li>
<li><strong>Input Box</strong> : this box lists the ID of the current model. The ID value can be changed to view other models. This can be done by adding a panel and searching in the input box for the new ID.</li>
<li><strong>Time Series Plot</strong> : If the test set includes actual results, then a time series plot will be displayed</li>
</ul>
</li>
<li><strong>Groups Test Metrics</strong><ul>
<li><strong>Top Group Test Metrics</strong> : Top group matrix based on the scorer that was used in the experiment</li>
<li><strong>Bottom Group Test Metrics</strong> : Bottom group matrix based on  the scorer that was used in the experiment</li>
<li><strong>Group Search</strong> : Entry field for selecting the groups to view. A graph of Actual vs Predicted values for the group will appear. This graph can be downloaded to your local machine.</li>
</ul>
</li>
</ol>
<p>4. Read the MLI TS Help panel to get a better idea on how to run the MLI on Time Series data for multiple groups, then click on <strong>Hide Help Panel</strong>.</p>
<p>5. Under <strong>Time Series Model</strong> click <strong>Show Summary</strong>, an image similar to the one below will appear:</p>
<p><img alt="mli-time-series-show-summary" src="img/c0cd5265497f1d78.jpg"></p>
<p><strong>Note:</strong> This is a summary of the experiment settings, it comes in handy when you want to compare the MLI settings/results to the MLI settings/results of another model for dataset side by side.</p>
<p>6. Select <strong>Hide Summary</strong></p>
<p>7. Hover over the <strong>Forecast Horizon</strong> of the <strong>R2 Time Series Plot</strong>.<br><strong>Note:</strong> R2 or the coefficient of determination is mainly used to analyze how well a variable can predict another one. In other words,  it is a statistical measure of how well the regression line approximates the real values. It represents the strength of the relationship between two time series or variables.The values observed in that range are the percentage of change of variable <strong>x</strong> that can be explained by changes in variable <strong>y</strong>.  The values of R2 range between 0 and 1, where 1 indicates that the values in this range can be entirely explained by pre-existing values.</p>
<p><img alt="mli-time-series-r2-plot" src="img/1d46b44a2b057ec7.jpg"></p>
<p>8. Under <strong>Top Groups Test Metrics</strong> and <strong>Bottom Group Test Metrics</strong>,  which Department(s) and Store(s) had the top R2 values? How about the Department(s) and Store(s) with the lowest  R2?</p>
<p><strong>Note:</strong> Columns is the number of unique cases in that time series composed of department and store appear of test data.</p>
<p><img alt="mli-time-series-group-test-metrics" src="img/f10964f269755b9d.jpg"></p>
<p>9. On the <strong>Group Search</strong> box:</p>
<ol type="1">
<li>Enter the following Dept and Store numbers: <code>3,12</code></li>
<li>(Dept, Store) options will appear below the <strong>Group Search</strong> box, select <code>3,12</code></li>
<li>A plot similar to the one below will appear with the actual and predicted values plotted for Department 3, Store 12:</li>
</ol>
<p><img alt="mli-group-dept-3-12-actual-vs-predicted" src="img/10c98501769fc4e9.jpg"></p>
<ol type="1">
<li>Hover over to the  <strong>Forecast Horizon</strong> and note the <strong>Actual</strong> plot in yellow and the <strong>Predicted</strong> plot in white.  While there hover over the peak point of the plot then compare the  actual vs predicted values generated by the model for store <code>3,12</code>.</li>
<li>This is the option to download the plot</li>
<li>From the <strong>Actual vs Predicted</strong> chart find the peak point and double click on it, a local Shapley value will appear right below the plot:</li>
</ol>
<p><img alt="mli-group-dept-3-12-peak-point-shapley-value" src="img/78b207e0f105fcaf.jpg"></p>
<p>At exactly the peak, it is clear that the lag of 52 weeks is the most important feature that drives this prediction that high.</p>
<ol type="1">
<li>While at the <strong>Actual vs Predicted</strong> chart find a point somewhere at the plateau and double click on it, a local Shapley value will appear right below the plot:</li>
</ol>
<p><img alt="mli-group-dept-3-12-plateau-point-shapley-value" src="img/e07f324e4eaf120e.jpg"></p>
<ol type="1">
<li>Explore other Departments and Stores <strong>Actual vs Predicted</strong> charts by clearing the &#34;3, 12&#34; value and entering another Department and Store in the Group Search box.</li>
</ol>
<p>10. Go to the top of the page and:</p>
<ol type="1">
<li>Select <strong>Add Panel</strong></li>
<li>On the new panel, click on the <strong>Select a model interpretation</strong>, then select the Time Series Model named : <code>Time Series Forecasting - Experiment 2: dahecaga</code>. This will bring in the pre-ran experiment&#39;s MLI results. Click on <strong>Show Summary</strong> for both experiments to compare experiment settings:</li>
</ol>
<p><strong>Note:</strong> the <strong>DAI Experiment Runtime</strong> for both experiments. The pre-ran experiment took more than seven hours to run.</p>
<p><img alt="mli-new-experiment-and-preran-experiment" src="img/5e184f0f10dad520.jpg"></p>
<ol type="1">
<li>For the pre-ran experiment, enter Department 3, Store 12 and find the peak point as well as the Shapley values associated with the peak point. Compare the values of the experiment you ran to the pre-ran experiment:</li>
</ol>
<p><img alt="mli-new-experiment-and-preran-experiment-2" src="img/ff0b7531a1d8d507.jpg"></p>
<p>When looking at both MLI results, we can see that for the pre-ran experiment the Shapley value that had the most importance for the peak value was <code>33 EWMA Lag</code> or the Exponentially Weighted Moving Average, which calculates the exponentially moving average of a target or feature lag, compared to the lag of 52 weeks for the new experiment. The feature that we see in the pre-ran experiment is a weighted moving average of what happened in various weeks over a course of 2 years; this is a more complex feature than the 52 weeks lag, and that is expected because we built a more complex model from the pre-ran experiment. Although the 52 weeks lag would help make the prediction for a peak value more accurate, our more complex model is trained to be able to predict any point in time, compared to our simple model which would make predictions based on the 1 year lag. Note that the 52 lag is indeed, one of the important variables in the complex model, but is not the most important one.</p>
<ol type="1">
<li>Find the shapley values for a point on the plateau for the pre-ran experiment and compare the values between the pre-ran experiment and the new experiment MLI results.</li>
</ol>
<h2>Deeper Dive and Resources</h2>
<ul>
<li><a href="http://docs.h2o.ai/driverless-ai/latest-stable/docs/userguide/interpret-ts.html?highlight=top%20group%20test%20metrics#multi-group-time-series-mli" target="_blank">H2O&#39;s DAI Multi Group Time Series MLI</a></li>
</ul>


      </google-codelab-step>
    
      <google-codelab-step label="Task 6: Analysis" duration="0">
        <p>Now we are going to take a look at the pre-ran Time-Series experiment and compare the results of the new experiment through the <strong>Projects Workspace</strong>:</p>
<p>1. Click on <code>H2O.ai</code> located at the top-left side of the MLI page, this will take you back to the <strong>Datasets Overview</strong> page.</p>
<p>2. Select <strong>Projects</strong>, then click on the <strong>Time Series Tutorial</strong> Project.</p>
<p>3. On the experiments section of the Projects page click on the pre-ran time-series experiment with name <strong>Time Series Forecasting - Experiment 2</strong>. The following image should appear:</p>
<p><img alt="pre-ran-experiment-settings-10-6-6" src="img/d3be4f18c21a1b9e.jpg"></p>
<p>This experiment was run in another environment with similar parameters except for the following settings:</p>
<ul>
<li><strong>Accuracy</strong> : 10</li>
<li><strong>Time</strong> : 6</li>
<li><strong>Interpretability</strong> : 6</li>
</ul>
<p>The above settings are recommended settings for timeseries problems, notice the high accuracy, time and lower interpretability compared to the settings from task 2. Time-series experiments are very special  cases as a result it is highly encouraged that the experiments are run with the default settings given by Driverless AI.</p>
<p>For a time-series experiment an <strong>Accuracy</strong> of 10 is highly encouraged because it forces many time splits (time splits are critical for stability and prevents overfitting) and allows for multiple window validation. If you must run a time-series experiment with anything lower than a 10, the lowest recommended setting for accuracy is a 5.</p>
<p><strong>Time</strong> is more flexible and can be ran with the DAI default value, or the lowest time value being 3. Regarding <strong>interpretability</strong>, use default results, for good results use interpretability values of either 5 or 6, anything less than 5 will tend to overfit.</p>
<p>Summary of suggested settings for Time-Series Experiments:</p>
<table>
<tr></tr>
<tr><td colspan="1" rowspan="1"><p>Accuracy</p>
</td><td colspan="1" rowspan="1"><p>10</p>
</td><td colspan="1" rowspan="1"><p>5</p>
</td></tr>
<tr><td colspan="1" rowspan="1"><p>Time</p>
</td><td colspan="1" rowspan="1"><p>Default</p>
</td><td colspan="1" rowspan="1"><p>3</p>
</td></tr>
<tr><td colspan="1" rowspan="1"><p>Interpretability</p>
</td><td colspan="1" rowspan="1"><p>Default</p>
</td><td colspan="1" rowspan="1"><p>5</p>
</td></tr>
</table>
<p>One important thing to note is why we changed the <strong>Scorer</strong>  that DAI suggested initially from <strong>RMSE</strong> to <strong>R2</strong> .  Even though DAI suggested RMSE as the scorer, we updated the scorer to R2 because for this particular dataset it&#39;s easier to generate similar results across different experiments since we can expect less fluctuation and more stability in terms of the results.</p>
<p>4. Click on <strong>&lt;</strong> located at the top-left side of the Experiments page, this will take you back to the <strong>Project Time Series Tutorial</strong>  page.</p>
<p>5. On the experiments section of the <strong>Projects</strong> page:</p>
<ol type="1">
<li>Click on the pre-ran time-series experiment with name <strong>Time Series Forecasting - Experiment 2</strong> and the name of the time-series experiment you ran for task 2</li>
<li>Then select <strong>Compare 2 Items</strong></li>
</ol>
<p><img alt="comparing-two-items" src="img/ce72e54d75d3ef9e.jpg"></p>
<p>6. A page with your experiment results and the results for the pre-ran experiment will show. An image similar to the one below will appear:</p>
<p><img alt="comparing-two-items-2" src="img/6ceb45b26017cdb7.jpg"></p>
<p><img alt="comparing-two-items-3" src="img/cd54c35bee5f8374.jpg"></p>
<p><em>Things to Note:</em></p>
<ol type="1">
<li>The experiment with the lower settings had less features scored compared to the pre-ran experiment. This means that DAI tested 45 features from which only 7 were found useful compared to the pre-ran experiment which tested 2700 features and found 18 features useful for feature engineering. At higher settings, DAI does a more thorough evaluation.</li>
<li>The lower settings experiment had an R2 value of .95146 compared to .95852 for the pre-ran experiment.</li>
<li>The variables under variable importance for the low settings are very simple lags compared to the pre-ran experiment that has very sophisticated variables.</li>
<li>On the <strong>Actual vs Predicted</strong> plots, the pre-ran experiment shows the points less dispersed compared to the low settings experiment. This translates to higher accuracy on the predictions.</li>
</ol>
<p>8. We have two models, a complex model, and a simple model. The complex model performed better than the simple model, but yielded some features that are not very easy to interpret, thus making the model less interpretable. On the other hand, we have a simple model that produced intuitive features but had a lower score than the complex model. Choosing the &#34;best&#34; or most accurate model depends on the specific application, and one has to decide if they want:</p>
<ol type="1">
<li>The most accurate or best possible model</li>
</ol>
<p>Or</p>
<ol type="1">
<li>The most interpretable model</li>
</ol>
<p>This decision needs to be made according to each particular case.</p>
<p>9. You have a finished model that you are satisfied with, what is next? What if you wanted to make predictions outside of the 26 week forecast horizon?</p>
<p>Some of the options are:</p>
<ul>
<li>Retrain entire pipeline with the most recent data</li>
<li>Build a new model with most recent data</li>
<li>Use recent model using <a href="http://docs.h2o.ai/driverless-ai/latest-stable/docs/userguide/time-series.html#using-a-driverless-ai-time-series-model-to-forecast" target="_blank">DAI&#39;s Test Augmentation</a></li>
</ul>
<p>Learn more about DAI&#39;s Test Augmentation by visiting H2O&#39;s documentation site.</p>
<h2>Deeper Dive and Resources</h2>
<ul>
<li><a href="http://docs.h2o.ai/driverless-ai/latest-stable/docs/userguide/time-series.html#using-a-driverless-ai-time-series-model-to-forecast" target="_blank">DAI&#39;s Test Augmentation</a></li>
</ul>


      </google-codelab-step>
    
      <google-codelab-step label="Task 7: Appendix A: Add the Datasets" duration="0">
        <h2>Add the Datasets</h2>
<p>Import H2O&#39;s training and test subsets of the Retail Store Forecasting dataset to the Datasets <strong>Overview Page</strong>.<br>1. Select <strong>+Add Dataset(or Drag and Drop)</strong> then click on <strong>File System</strong></p>
<p><img alt="retail-store-add-dataset" src="img/4d55a28713fb2def.jpg"><br>2. Type the following path into the search bar: &#34;/data/TimeSeries/walmart/&#34;<br>3. Select the following sets from the list:<br>walmart_tts_small_test.csv<br>walmart_tts_small_train.csv</p>
<p><img alt="retail-store-import-datasets" src="img/621277d407ba6cde.jpg"></p>
<p>4.  <strong>Click to Import Selection</strong></p>
<p>5. Verify that both dataset were added to the <strong>Datasets Overview</strong>, your screen should look similar to the  page below:</p>
<p><img alt="retail-store-train-test-datasets" src="img/7b753b452ee4b80a.jpg"></p>


      </google-codelab-step>
    
      <google-codelab-step label="Task 8 Next Steps" duration="0">
        <p>Check out Driverss AI next tutorial [Natural Language Processing Tutorial - Sentiment Analysis]()</p>
<p>Where you will learn:</p>
<ul>
<li>How to launch a sentiment analysis experirement</li>
<li>Sentiment Analysis Experiment settings</li>
<li>NLP Concepts</li>
<li>Driverless Ai NLP Recipe</li>
<li>and more....</li>
</ul>


      </google-codelab-step>
    
  </google-codelab>

  <script src="../assets/codelab-elements/native-shim.js"></script>
  <script src="../assets/codelab-elements/custom-elements.min.js"></script>
  <script src="../assets/codelab-elements/prettify.js"></script>
  <script src="../assets/codelab-elements/codelab-elements.js"></script>

</body>
</html>
